---
title: "Measuring Forecasting Proficiency: An Item Response Theory Approach"
author: "Fabio Setti"
institute: "Fordham University"

engine: shinylive

bibliography: Additional files/R packages.bib
csl: Additional files/apa.csl

title-slide-attributes:
  data-transition: "zoom"
  data-visibility: "uncounted"

format:
  revealjs:
    footer: "IMPS 2025"
    width: 1280
    height: 720
    chalkboard: true
    slide-number: c/t 
    theme: Fabio_theme/Fabio_theme.scss
    navigation-mode: linear
    controls: false
    embed-resources: false
    auto-stretch: false
    resource-path: 
      - shinylive-sw.js
    header-includes:
      - <script src="Fabio_theme/Fabio_theme.js"></script>
      - <script src="shinylive-sw.js"></script>

filters:
  - shinylive
editor: source
---


## Quantile Forecasts


```{r}
#| warning: false

# ggplot defaults and tidyverse

library(tidyverse)
theme_set(theme_classic(base_size = 20, 
                        base_family = 'serif'))
```



The Forecasting Proficiency Test [FPT\; @Himmelstein_etal_2024] is a test developed to measure forecasting proficiency. The FTP uses *quantile forecast* items:




:::: {.columns}

::: {.column width="40%"}

::: {.fragment fragment-index=1}

<center> **FPT sample item:** </center>
:::

::: {.r-stack}

![](Additional files/images/Sample_questions.png){.fragment fragment-index=1}

![](Additional files/images/Sample_questions_answers.PNG){.fragment fragment-index=2}
:::

:::

::: {.column width="60%"}


::: {.fragment fragment-index=2}

Quantile forecasting items are designed to elicit an individual's subjective cumulative distribution function (CDF) regarding a future continuous outcome

:::


::: {.fragment fragment-index=3}

- Each participant provides 5 monotonically increasing responses

- Responses are unbounded

- *Forecast accuracy* is the measure of interest 
:::

::: {.fragment fragment-index=4}
**GOAL:** in IRT fashion, modeling forecast accuracy by positing a statistical model that accounts for both *person* and *item* features
:::

:::

::::


## Defining Forecast Accuracy



Responses to FTP quantile forecast items are on very different scale (e.g. dollars/gallon, thousands of dollars, percentages,...). We define the outcome measure, *historically scaled accuracy*, as




$$
Y_i = \frac{\hat{Y}_i - Y_{\mathrm{res},i}}{SD_{Y_{\mathrm{hist},i}}}
$$

:::: {.columns}
::: {.column width="55%"}


<ul style="font-size: 24px">  

<li>  $\hat{Y}_i$: Reported forecast for item $i$ at any quantile.   </li>

<li>  $Y_{\mathrm{res},i}$: The resolution for item $i$.   </li>

<li>  $SD_{Y_{\mathrm{hist},i}}$: The $SD$ of the historical time series of item $i$.    </li>

</ul>


:::
::: {.column width="45%"}

::: {.fragment fragment-index=1}

$Y_i$: SD units away from the resolution.

:::

::: {.r-stack}

::: {.fragment fragment-index=1}

```{r}
ggplot() +
  xlim(c(-3, 3)) +
  ylim(c(0, 5)) +
  xlab(expression(Y[i])) +
   geom_segment(aes(x = 0, xend = 0, y = 0, yend = 4), linetype = 2, 
                col = "#1b305c",
                size = 2)+
  annotate("text", x = -2, y = 1, label = "Perfect Forecast",
           size = 7) +
  theme(axis.ticks.y = element_blank(),
        axis.title.y =element_blank(),
        axis.line.y = element_blank(),
        axis.text.y =  element_blank())

```
:::

::: {.fragment fragment-index=2}

```{r}
ggplot() +
  xlim(c(-3, 3)) +
  ylim(c(0, 5)) +
  xlab(expression(Y[i])) +
   geom_segment(aes(x = 2, xend = 2, y = 0, yend = 4), linetype = 2,
                col = "#1b305c",
                size = 2)+
  annotate("text", x = 0, y = 1, label = "2 SD Above \n Resolution",
           size = 7) +
  theme(axis.ticks.y = element_blank(),
        axis.title.y =element_blank(),
        axis.line.y = element_blank(),
        axis.text.y =  element_blank())


```

:::

::: {.fragment fragment-index=3}

```{r}
ggplot() +
  xlim(c(-3, 3)) +
  ylim(c(0, 5)) +
  xlab(expression(Y[i])) +
   geom_segment(aes(x = -1, xend = -1, y = 0, yend = 4), linetype = 2,
                col = "#1b305c",
                size = 2)+
  annotate("text", x = 0, y = 1, label = "1 SD Below \n Resolution",
           size = 7) +
  theme(axis.ticks.y = element_blank(),
        axis.title.y =element_blank(),
        axis.line.y = element_blank(),
        axis.text.y =  element_blank())


```

:::

:::


:::
::::

## Assumptions About Item Behavior

```{r}
source("Functions.R")
```

:::: {.columns}
::: {.column width="50%"}

**Assumption 1:** Some items are either unbiased or bias (*irreducible uncertainty*) 

::: {.panel-tabset}

### Unbiased Item

```{r}
#| eval: true
#| echo: false 
#| code-line-numbers: false

Model_plot(title = "")

```


### Biased Item 

```{r}
#| eval: true
#| echo: false 
#| code-line-numbers: false

Model_plot(b = 2, title = "")

```

 
:::
 
:::

::: {.column width="50%"}

**Assumption 2:** Good forecasters will more closely approach the expected means at the 5 quantiles 


::: {.panel-tabset}

### Average Forecaster


```{r}
#| eval: true
#| echo: false 
#| code-line-numbers: false

Model_plot_full(b = -1, df = 2000, sd = 1, title = "Expected Distribution for Average Forecaster")

```


### Good Forecaster



```{r}
#| eval: true
#| echo: false 
#| code-line-numbers: false

Model_plot_full( b = -1, df = 2000, sd = .2, title = "Expected Distribution for Good Forecaster")

```

:::

:::

::::


## The Proposed Model


We model $Y_{jiq}$, the accuracy of person $j$ to item $i$ at quantile $q$. 


:::: {.columns}
::: {.column width="40%"}

$$Y_{jiq} \sim \mathrm{Student\ T}(\mu_{iq}, \sigma_{ji}, \mathrm{df}_i) \\
\mu_{iq} = b_i + Q_q \times d_i \\
\sigma_{ji} = \frac{\sigma_i}{\mathrm{Exp}[a_i \times \theta_j]}$$


<ul style="font-size: 22px">  

::: {.fragment fragment-index=1}
<li>  $b_i$: item bias  </li>
:::

::: {.fragment fragment-index=2}
<li>  $d_i$: expected quantile distance. $Q_q$ is a vector of constants that ensures monotonicity of $\mu_{iq}$  </li>
:::

::: {.fragment fragment-index=3}
<li>  $\sigma_i$: item difficulty </li>
:::

::: {.fragment fragment-index=4}
<li>  $\theta_j$: Forecasting ability, the only **person parameter** in the model </li>
:::

::: {.fragment fragment-index=5}
<li>  $a_i$: item discrimination (i.e. the effect of $\theta_j$ on $\sigma_i$)  </li>
:::

</ul>


:::
::: {.column width="60%"}

<iframe width="90%" height="550px" src="https://quinix45.github.io/shinylive_apps/t_model/"> </iframe>

:::
::::


## Data Collection

Item responses were collected across 5 waves of a 7 Wave study. 

</br>

:::: {.columns}
::: {.column width="40%"}


<ul style="font-size: 26px">  

<li>  **32 items** divided across 6 forms (A, B, C, D, E, X)  and **1194 participants** </li>


<li> Diverse item domains: Financial, political, technology, energy... </li>


<li> 1 week interval between waves, and 1 month from resolution at wave 7  </li>

</ul>


</br>




:::
::: {.column width="60%"}

\renewcommand{\arraystretch}{4}
```{r}
#| eval: true
#| echo: false
#| code-line-numbers: false

library(kableExtra)

wave_tab <- t(data.frame(c("Form E+A", "Form B+X", "Form C+X", "Form D+X", "Form E+A"),
                         c("Form A+B", "Form C+X", "Form D+X", "Form E+X", "Form A+B"),
                         c("Form B+C", "Form D+X", "Form E+X", "Form A+X", "Form B+C"),
                         c("Form C+D", "Form E+X", "Form A+X", "Form B+X", "Form C+D"),
                         c("Form D+E", "Form A+X", "Form B+X", "Form C+X", "Form D+E")))

colnames(wave_tab) <- paste("wave", c(1, 2, 4, 6, 7))
rownames(wave_tab) <- paste("order", 1:5)


kable(wave_tab) %>% 
  row_spec(0, bold = T) %>% 
  column_spec(1, bold = T) %>% 
  kable_classic(full_width = T, html_font = "Palatino Linotype") %>% 
  kable_styling(font_size = 22)
  
```
<div style="font-size: 16px"> *note*. Table 2 from @Zhu_etal_2024. The full experimental designed is detailed in both @Zhu_etal_2024 and @Himmelstein_etal_2024.</div>



:::
::::

:::: {.columns}


::: {.column width="33%"}

**Form B,C,D:** completed 1 time in either waves 2,4,6 (responses treated as *in sample*)

:::

::: {.column width="33%"}

**Form A, E:** completed 2 times, waves 1, and 7 (responses treated as *out of sample*)

:::

::: {.column width="33%"}

**Form X:** completed 3 times in waves 2, 4, 6. (only responses from wave 2 will be used here, *in sample*)

:::
::::



## Model Estimation and Item Parameters

All models were estimated in PyMC [@pymc2023] using Markov Chain Monte Carlo (MCMC) estimation (warmup = 1000, draws = 5000, ~ 40 minutes). All Rhats $\leq 1.01$. 

:::: {.columns}
::: {.column width="70%"}


```{r}
#| eval: true
#| echo: false
#| code-line-numbers: false
# #| out-width: "80%"
#| fig-align: left

mod_res <- rio::import("Additional files/summary.csv")

design <- c(
"
 AABBCC
 #DDEE#
 "
)


# create plots

b_plot <- mod_res %>% 
  filter(parameter == "b") %>% 
ggplot(aes(x = reorder(item, mean), y = mean)) +
  geom_pointrange(aes(ymin=mean-sd, ymax=mean+sd),
                  fatten = 1.5) +
  coord_flip() +
  xlab("item") +
  ggtitle("") +
  ylab("b") +
  theme(axis.text=element_text(size=10))

d_plot <- mod_res %>% 
  filter(parameter == "d") %>% 
ggplot(aes(x = reorder(item, mean), y = exp(mean))) +
  geom_pointrange(aes(ymin=exp(mean-sd), ymax=exp(mean+sd)),
                  fatten = 1.5) +
  coord_flip() +
  xlab("") +
  ggtitle("") +
  ylab("d") +
  theme(axis.text=element_text(size=10))


sigma_plot <- mod_res %>% 
  filter(parameter == "sigma") %>% 
ggplot(aes(x = reorder(item, mean), y = exp(mean))) +
  geom_pointrange(aes(ymin=exp(mean-sd), ymax=exp(mean+sd)),
                  fatten = 1.5) +
  coord_flip() +
  xlab("") +
  ggtitle("") +
  ylab("\u03C3") +
  theme(axis.text=element_text(size=10))

a_plot <- mod_res %>% 
  filter(parameter == "a") %>% 
ggplot(aes(x = reorder(item, mean), y = exp(mean))) +
  geom_pointrange(aes(ymin=exp(mean-sd), ymax=exp(mean+sd)),
                  fatten = 1.5) +
  coord_flip() +
  xlab("") +
  ggtitle("") +
  ylab("a") +
  theme(axis.text=element_text(size=10))


df_plot <- mod_res %>% 
  filter(parameter == "nu") %>% 
ggplot(aes(x = reorder(item, mean), y = mean)) +
  geom_pointrange(aes(ymin=mean-sd, ymax=mean+sd),
                  fatten = 1.5) +
  coord_flip() +
  xlab("") +
  ggtitle("") +
  ylab("df") +
  theme(axis.text=element_text(size=10))



gridExtra::grid.arrange(b_plot, d_plot, sigma_plot, a_plot, df_plot,
                        nrow = 1)
```


:::
::: {.column width="30%"}


</br>


```{r}
#| eval: true
#| echo: false
#| code-line-numbers: false

# correlation among item parameters (maybe highlight high correlations later)


`%!in%` <- Negate(`%in%`) 

par_tab <- mod_res %>% 
  filter(parameter %!in% c("theta", "G_diff")) %>% 
    select(parameter, mean, index) %>% 
      pivot_wider(names_from = parameter, values_from = mean) %>% 
          mutate(a = exp(a),
                 d = exp(d),
                 sigma = exp(sigma))


colnames(par_tab)[5] <- "df"

cor_tab <- data.frame(round(cor(par_tab[,-1], use = "complete.obs"), 2))
  

kableExtra::kbl(cor_tab, caption = "BetweenItem Parameters Correlations") %>% 
  row_spec(0, bold = T) %>% 
  column_spec(1, bold = T) %>% 
  kable_classic(full_width = T, html_font = "Palatino Linotype") %>% 
  kable_styling(font_size = 18)

```


:::
::::


## Person Parameter: $\theta$

:::: {.columns}
::: {.column width="40%"}

The distribution of $\theta$ for the 1194 forecasters (better forecasters have higher $\theta$ values).



```{r}

mod_res %>% 
  filter(parameter == "theta") %>% 
    ggplot(aes(x = mean)) +
    geom_density() +
    xlab("\u03b8")+ 
    ylab("") +
    theme(axis.text=element_text(size=16),
          plot.title = element_text(face="bold", hjust = 0.5),
           plot.margin = margin(t = 0,  # Top margin
                             r = 0,  # Right margin
                             b = 0,  # Bottom margin
                             l = 0)) +
    ggtitle("\u03b8 Distribution of 1194 Forecasters") 

```
<div style="font-size: 16px; margin-top: -16px; text-align:center;"> *note*. The scale $\theta$ parameter was identified by enforcing a standard normal prior.</div>



:::
::: {.column width="60%"}

<div style="font-size: 22px"> Forecasters who consistently approach the expected forecasts are rewarded. </div>


![](Additional files/theta_plot.png){width=80%}
<div style="font-size: 14px"> *note*. In the case of the two top panels, missing person forecast were outside the $Y_{jiq} = [-9; 9]$ range.</div>

:::
::::


## Predicting Out of Sample Accuracy


<div style="font-size: 24px"> As per the study design, Waves 1 and 7 responses were treated as *outcome* and Waves 2,4, 6 were treated as *predictors*. </div>




:::: {.columns}
::: {.column width="30%"}


</br>
</br>

<div style="font-size: 26px; padding-top: 14px;"> **S-scores (SS):** A proper scoring rule that is normally used to score quantile forecasts (smaller SS, better forecast) </div>







:::
::: {.column width="70%"}

![](Additional files/OUS_acc_plot.png){width=95%}

:::
::::




## Expected Item Information

One advantage of the $\theta$ metric is that it allows for the calculation of *expected item information*, $\mathrm{EI}(\theta)$ :


:::: {.columns}
::: {.column width="40%"}

$$Y_{jiq} \sim \mathrm{Student\ T}(\mu_{iq}, \sigma_{ji}, \mathrm{df}_i) \\
\mu_{iq} = b_i + Q_q \times d_i \\
\sigma_{ji} = \frac{\sigma_i}{\mathrm{Exp}[a_i \times \theta_j]}$$


<ul style="font-size: 22px">

<li> Items with higher $\sigma_i$ measure more skilled forecasters better (*difficulty*) </li>

<li> Higher $a_i$ implies better measurement within a narrower interval of $\theta$ (*discrimination*) </li>

<li>  $df_i$ functions in a similar way to $\sigma_i$.  </li>

<li>  The parameters within $\mu_{iq}$ do not influence $\mathrm{E} \mathrm{I}(\theta)$ much. </li>

</ul>


<!-- <div style="font-size: 14px"> **note:** $\mathrm{E} \mathrm{I}(\theta)$ is computed by integrating over $Y_{jiq}[-10;10]$. The current integral assumes that any value of $Y_{jiq}$ within the integration range is equally likely, which is not accurate. This implementation is a general proof of concept. </div> -->


:::
::: {.column width="60%"}


<iframe width="90%" height="550px" src="https://quinix45.github.io/shinylive_apps/Einfo_t_model/"> </iframe>


:::
::::




## Stability of Item Parameters

Given the complexity of the FPT items, item parameters are likely to change depending on many factors. Still, there seems to be reasonable stability even after a month between Wave 1 and Wave 7 (*test-retest*):

:::: {.columns}
::: {.column width="30%"}

</br>

Item parameters are fairly stable. $\theta$, on the other hand, shows moderate correlation.

<ul style="font-size: 22px">  

<li>  Time from resolution still has some impact on item parameters and should be accounted for in the model.   </li>

<li>  It is likely that other factors beyond person/item characteristics influence response accuracy.   </li>

</ul>


:::
::: {.column width="70%"}


<center>
![](Additional files/W1_W7_parameters.png){width=80%}
</center>
<div style="font-size: 14px"> *note*. Only items from Waves 1 and 7. The $a_i$ parameter requires higher sample sizes to stably estimate, so it was fixed to 1. </div>

:::
::::




## Takeaways



## Acknowledgments








## References 

<div id="refs"> </div>


# Appendix


## Negative Log-Likelihood of $\theta$



Negative log-likelihood function of $\theta$ given item parameters and participant response:

<iframe width="90%" height="500px" src="https://quinix45.github.io/shinylive_apps/MLE_theta_model_t/"> </iframe>




## Item Parameters By Item



```{r}
#| eval: true
#| echo: false
#| code-line-numbers: false
# #| out-width: "80%"


# create plots

b_plot <- mod_res %>% 
  filter(parameter == "b") %>% 
ggplot(aes(x = reorder(item, mean), y = mean)) +
  geom_pointrange(aes(ymin=mean-sd, ymax=mean+sd),
                  fatten = 1.5) +
  coord_flip() +
  xlab("item") +
  ggtitle("") +
  ylab("b") +
  theme(axis.text=element_text(size=10))

d_plot <- mod_res %>% 
  filter(parameter == "d") %>% 
ggplot(aes(x = reorder(item, mean), y = exp(mean))) +
  geom_pointrange(aes(ymin=exp(mean-sd), ymax=exp(mean+sd)),
                  fatten = 1.5) +
  coord_flip() +
  xlab("") +
  ggtitle("") +
  ylab("d") +
  theme(axis.text=element_text(size=10))


sigma_plot <- mod_res %>% 
  filter(parameter == "sigma") %>% 
ggplot(aes(x = reorder(item, mean), y = exp(mean))) +
  geom_pointrange(aes(ymin=exp(mean-sd), ymax=exp(mean+sd)),
                  fatten = 1.5) +
  coord_flip() +
  xlab("") +
  ggtitle("") +
  ylab("\u03C3") +
  theme(axis.text=element_text(size=10))

a_plot <- mod_res %>% 
  filter(parameter == "a") %>% 
ggplot(aes(x = reorder(item, mean), y = exp(mean))) +
  geom_pointrange(aes(ymin=exp(mean-sd), ymax=exp(mean+sd)),
                  fatten = 1.5) +
  coord_flip() +
  xlab("") +
  ggtitle("") +
  ylab("a") +
  theme(axis.text=element_text(size=10))


df_plot <- mod_res %>% 
  filter(parameter == "nu") %>% 
ggplot(aes(x = reorder(item, mean), y = mean)) +
  geom_pointrange(aes(ymin=mean-sd, ymax=mean+sd),
                  fatten = 1.5) +
  coord_flip() +
  xlab("") +
  ggtitle("") +
  ylab("df") +
  theme(axis.text=element_text(size=10))



gridExtra::grid.arrange(b_plot, d_plot, sigma_plot, a_plot, df_plot,
                        nrow = 1)
```

